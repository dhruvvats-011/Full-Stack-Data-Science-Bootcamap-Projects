{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05e0ea0-281d-41e4-a90d-333642a0065a",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.What are Corpora?\n",
    "\n",
    "Corpora (plural of corpus) refer to large collections of text or speech data that are used for linguistic analysis and natural language processing (NLP) tasks. A corpus can contain a variety of text data like books, articles, social media posts, or transcriptions of speech. They serve as the foundational data for training and testing NLP models.\n",
    "Example: The Brown Corpus or Wikipedia dumps are examples of corpora used in NLP research.\n",
    "\n",
    "2.What are Tokens?\n",
    "\n",
    "Tokens are the individual components or units that make up a text. In the context of NLP, a token is typically a word, punctuation mark, or other meaningful elements. The process of breaking a text into tokens is called tokenization.\n",
    "Example: For the sentence \"I love cats!\", the tokens are [\"I\", \"love\", \"cats\", \"!\"].\n",
    "\n",
    "3.What are Unigrams, Bigrams, Trigrams?\n",
    "\n",
    "Unigrams are single tokens or words in a text.\n",
    "Bigrams are sequences of two consecutive words.\n",
    "Trigrams are sequences of three consecutive words.\n",
    "Example:\n",
    "Unigrams: \"I\", \"love\", \"cats\"\n",
    "Bigrams: \"I love\", \"love cats\"\n",
    "Trigrams: \"I love cats\"\n",
    "\n",
    "4.How to generate n-grams from text?\n",
    "\n",
    "N-grams are generated by splitting the text into sequences of n consecutive words. This can be done using Python libraries like nltk or sklearn. Here how you can generate n-grams:\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "from nltk import ngrams\n",
    "\n",
    "text = \"I love cats\"\n",
    "words = text.split()\n",
    "bigrams = list(ngrams(words, 2))  # Bigrams\n",
    "trigrams = list(ngrams(words, 3))  # Trigrams\n",
    "\n",
    "print(bigrams)  # Output: [('I', 'love'), ('love', 'cats')]\n",
    "print(trigrams)  # Output: [('I', 'love', 'cats')]\n",
    "\n",
    "5.Explain Lemmatization:\n",
    "\n",
    "Lemmatization is the process of reducing a word to its base or root form (called a lemma). Unlike stemming, which just chops off prefixes and suffixes, lemmatization considers the word's meaning and returns the correct dictionary form.\n",
    "Example:\"running\" → \"run\", \"better\" → \"good\"\n",
    "\n",
    "6. Explain Stemming:\n",
    "\n",
    "Stemming is the process of reducing a word to its root form by removing suffixes. It is a simpler approach than lemmatization and doesn't always result in a valid word. Stemming often uses algorithms like the Porter Stemmer or Lancaster Stemmer.\n",
    "Example: \"running\" → \"run\", \"better\" → \"bet\"\n",
    "\n",
    "7.Explain Part-of-speech (POS) tagging:\n",
    "\n",
    "Part-of-speech (POS) tagging is the process of assigning a grammatical category (such as noun, verb, adjective, etc.) to each word in a sentence. This helps understand the syntactic structure and role of each word in the text.\n",
    "Example: In the sentence \"The cat runs fast\", POS tagging would assign:\n",
    "\"The\" → Determiner (DT)\n",
    "\"cat\" → Noun (NN)\n",
    "\"runs\" → Verb (VBZ)\n",
    "\"fast\" → Adverb (RB)\n",
    "\n",
    "8.Explain Chunking or shallow parsing:\n",
    "\n",
    "Chunking (or shallow parsing) is a technique in NLP that involves grouping words into larger, meaningful units or chunks, typically using POS tags. The goal is to divide the text into constituent parts, such as noun phrases (NP) or verb phrases (VP).\n",
    "Example: In the sentence \"The big cat runs fast\", chunking could identify:\n",
    "\"The big cat\" as a noun phrase (NP)\n",
    "\"runs fast\" as a verb phrase (VP)\n",
    "\n",
    "9.Explain Noun Phrase (NP) chunking:\n",
    "\n",
    "Noun Phrase (NP) chunking is a specific type of chunking that focuses on identifying noun phrases in a text. A noun phrase typically consists of a noun and its associated modifiers (like adjectives or determiners).\n",
    "Example: In the sentence \"The big brown cat\", the noun phrase (NP) chunk would be \"The big brown cat\".\n",
    "Explain Named Entity Recognition:\n",
    "\n",
    "Named Entity Recognition (NER) is a process in NLP that identifies and classifies named entities (such as people, organizations, dates, locations, etc.) in a text. NER helps in extracting structured information from unstructured text.\n",
    "Example: In the sentence \"Apple Inc. was founded by Steve Jobs in 1976\", NER might identify:\n",
    "\"Apple Inc.\" as an organization\n",
    "\"Steve Jobs\" as a person\n",
    "\"1976\" as a date\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
